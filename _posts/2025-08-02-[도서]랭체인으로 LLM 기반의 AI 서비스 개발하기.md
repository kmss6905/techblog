---
layout: post
title: "[Book] 랭체인으로 LLM 기반의 AI 서비스 개발하기"
categories:
- "AI"
tags:
- "LLM"
- "LangChain"
- "RAG"
- "Book"
date: "2025-08-02 00:00:00 +0900"
toc: true
---

## 서론

언어모델로 부터 시작해서 LLM의 개념, 종류, 특징, 한계, 사용시 주의점 등등 을 앞서 살펴보았다. 입맛에 맞게 LLM을 활용하기 위해서는 파인튜닝(Fine Tuning) 이 필요하지만, 현실적인 어려움으로 인해 RAG를 선호한다. 이 장에서는 RAG의 개념부터 활용방법에 대해서 알아본다.

## RAG 란?

RAG(Retrieval-Augmented Generation)는 영어 그대로 검색증강생성 기술이다.

쉽게 설명하자면, LLM이 텍스트를 생성할 때 관련 정보를 찾아 보고(retrieval), 그 정보를 활용하여 새로운 텍스트를 만드는 (generation) 기술이라고 할 수 있다.

가령 RAG를 사용하는 LLM은 특정 질문에 답하기 위해 인터넷에서 정보를 검색하고, 그 정보를 바탕으로 상세하고 정확한 답변을 생성할 수 있다.

## RAG 구현 과정

결국 RAG 의 구현은 두 가지 과정으로 나뉘어진다.

1. **정보 검색(retrieval)**
2. **텍스트 생성(generation)**

### 1. 정보 검색

정보 검색의 과정은 다음과 같다. 우리가 구글에 원하는 것을 검색해서 정보를 얻어내는 과정과 유사하다.

1. 질문입력 - 필요한 정보를 찾기 위해 구글이나 네이버에 질문을 하거나 키워드를 입력 (이때 이를 query 라고 함. ) 
2. 검색 - 검색 엔진은 해당 쿼리와 관련된 정보를 데이터 베이스나 인터넷에서 찾는다.
3. 유사도검색 - 검색 엔진은 쿼리와 데이터 베이스(혹은 인터넷)에 있는 문서들 사시의 유사도를 계산.(키워드 검색[^4], 시멘틱 검색[^5])
4. 랭킹처리 - 검색결과로 찾아낸 문서들 중에서 어떤 것이 질문과 가장 관련이 높은지를 결정. 

> 랭킹처리와 관련해서도 여러가지 방법이 존재한다. (페이지랭크[^1], TF-IDF[^2], 클릭률[^3])

### 2. 텍스트 생성

1. (검색엔진의 경우) 결과반환
    > 랭킹이 매겨진 문서 리스트를 사용자에게 보여줌.

2. (LLM의 경우) 텍스트 생성
    > 사용자의 질문과 검색 결과로 텍스트를 생성한다.
    > 
    > 예시) 
    > query - 마이클 잭슨의 가장 유명한 노래는?
    > database or internet - Billie Jean
    >
    > query + Billie Jean => LLM(generation) => answer
    >
    > generation(llm) - 마이클 잭슨의 가장 유명한 노래 중 하나는 Billie Jean 이며, bra bra..
    
LLM 은 제공된 정보를 활용하여 구체적이고 정보에 기반한 텍스트를 생성할 수 있음. 

## RAG 구현 시 필요한 것

### 1. 데이터

특별한 형식을 요구하지는 않는다. CSV, JSON, PDF, DB도 가능하다. 단, 중요한 것은 데이터의 형식이 아닌 규범과 규제를 고려해야한다. 특히 사용하려는 데이터에 개인정보가 포함되어 있는지, 상업적 용도로 사용할 경우 해당되는 지를 확인해야한다.

흭득한 데이터는 두 가지 방법으로 사용가능하다.

1. 시맨틱검색
2. 벡터 검색

### 임베딩

결국 모든 데이터를 컴퓨터가 이해할 수 있도록 정보를 숫자(벡터)로 바꿔야한다. 아래의 예시에서 첫번째 숫자는 '과일(fruit)' 을 두번 째 숫자는 '기술(technology)' 을 나타낸다고 했을 때 아래와 같이 변환될 수 있다.

*  '사과': `[1, 0]`
*  '바나나': `[0.9, 0.1]`
*  '사과': `[0.1, 0.9]`

### 임베딩모델

임베딩을 위해서는 **임베딩모델**[^6] 이 필요하다.

여러 임베딩 모델이 존재한다.(Word2Vec[^7], Glove[^8], Open AI Embeding Model[^9])

```py
# Open AI Embeding Model 사용
from openai import OpenAI

client = OpenAI(api_key="sk-xxxx")

document = ['제프리 힌튼', '교수', '토론토 대학', '사임']

response = client.embeddings.create(
    input=document,
    model='text-embedding-ada-002'
)
response
```

실행결과
```

CreateEmbeddingResponse(data=[Embedding(embedding=[-0.025331685319542885, -0.019289137795567513, -0.007674173451960087, -0.016426879912614822, -0.008012942969799042, 0.028055671602487564, -0.005883533041924238, 0.004137831274420023, -0.002872629789635539, 0.006886015180498362, ...
```

### 벡터 데이터 베이스

벡터 데이터 베이스는 말 그대로 벡터를 저장하는 저장소.

벡터 데이터베이스는 단순히 벡터를 저장하는 것 외에도 데이터를 관리하며, 검색하는 일도 한다.

일반 데이터베이스와 달리 벡터 테이터베이스는 데이터의 정확한 값 대신 데이터 간의 '유사성'을 바탕으로 검색하는 데 사용됩니다.

일반적인 데이터베이스에서 원하는 데이터를 검색할 때
```sql 
SELECT * FROM customers WHERE age >= 30;
```

벡터 데이터베이스에서 검색할 때

사용자가 "배송 상태를 어떻게 확인할 수 있죠?" 라고 질문을 하게 되면 백터 데이터베이스에 질의를 해야하기 때문에
먼저 **임베딩 처리 과정** 을 거쳐 **벡터** 로 변환해야한다. 이후 아래와 같이 질의를 할 수 있다.

```text
POST /search
{
    "query_vector": [0.13, -0.24, 0.33, ..., 0.78],
    "top_k": 5
}
```

<div class="mermaid">
graph TD
    contents(contents)
    application-query(application)
    model(embedding model)
    embedding(embedding)
    db[(Vector Database)]
    contents --> model
    application-query --> model
    model --> embedding
    embedding --> db
</div>

저장된 문서벡터들과 질문 벡터간의 유사성(이때 코사인 유사도, 질문 벡터 간의 유사성)을 계산하여, 검사 결과에 따라 점수가 가장 높은 (상위 랭크) 상위 N개의 벡터들이 반환되고 사용자에게 보여준다.


[^1]: **페이지랭크(PageRank):** 웹페이지의 상대적 중요도를 결정하는 알고리즘. 중요한 페이지로부터 많은 링크를 받을수록 중요도가 높다고 평가합니다.
[^2]: **TF-IDF(Term Frequency-Inverse Document Frequency):** 문서 집합에서 특정 단어가 특정 문서 내에서 얼마나 중요한지를 나타내는 통계적 수치. 단어의 빈도와 역문서 빈도를 곱하여 계산합니다.
[^3]: **클릭률(CTR, Click-Through Rate):** 광고나 링크가 노출된 횟수 대비 클릭된 횟수의 비율. 사용자의 관심도를 측정하는 주요 지표입니다.
[^4]: **키워드 검색:** 사용자가 입력한 특정 단어나 구문이 포함된 문서를 찾는 가장 일반적인 검색 방식입니다.
[^5]: **시멘틱 검색(Semantic Search):** 검색어의 의미와 맥락, 사용자의 의도까지 파악하여 관련성 높은 정보를 제공하는 검색 기술입니다.
[^6]: **임베딩 모델(Embedding Model):** 텍스트, 이미지 등의 데이터를 컴퓨터가 이해할 수 있는 숫자 벡터로 변환하는 모델. 데이터의 의미적, 문법적 특징을 벡터 공간에 표현합니다.
[^7]: **Word2Vec:** "비슷한 문맥에서 등장하는 단어는 비슷한 의미를 가진다"는 분포 가설을 기반으로 단어를 벡터로 변환하는 모델입니다.
[^8]: **GloVe(Global Vectors for Word Representation):** 말뭉치 전체의 통계 정보를 활용하여 단어의 의미를 벡터 공간에 표현하는 모델입니다.
[^9]: **OpenAI Embedding Model:** 텍스트를 의미와 문맥을 이해하는 숫자 벡터로 변환하는 OpenAI의 모델입니다.